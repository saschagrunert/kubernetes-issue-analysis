apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: kubernetes-analysis-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 0.5.1, pipelines.kubeflow.org/pipeline_compilation_time: '2020-05-15T19:30:52.445945',
    pipelines.kubeflow.org/pipeline_spec: '{"inputs": [{"default": "", "name": "pr",
      "optional": true, "type": "String"}, {"default": "", "name": "commit", "optional":
      true, "type": "String"}], "name": "Kubernetes Analysis"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 0.5.1}
spec:
  entrypoint: kubernetes-analysis
  templates:
  - name: build-image
    container:
      args:
      - |+
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis
        cp -r /tmp/inputs/input-1/data data/vectorizer.pickle
        cp -r /tmp/inputs/input-2/data data/selector.pickle
        cp -r /tmp/inputs/input-3/data data/model.h5

        echo "git diff:"
        git diff --name-only

        buildah bud --isolation=chroot -f Dockerfile-deploy                     -t quay.io/saschagrunert/kubernetes-analysis-kfserving:{{inputs.parameters.commit}}

        buildah login -u saschagrunert+kubeflow                     -p $(cat /secrets/quay/password) quay.io

        buildah push quay.io/saschagrunert/kubernetes-analysis-kfserving:{{inputs.parameters.commit}}

        if [[ -z "{{inputs.parameters.pr}}" ]]; then
            buildah tag quay.io/saschagrunert/kubernetes-analysis-kfserving:{{inputs.parameters.commit}} quay.io/saschagrunert/kubernetes-analysis-kfserving:latest
            buildah push quay.io/saschagrunert/kubernetes-analysis-kfserving:latest
        fi

      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      parameters:
      - {name: commit}
      - {name: pr}
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
      - {name: train-vectorizer, path: /tmp/inputs/input-1/data}
      - {name: train-selector, path: /tmp/inputs/input-2/data}
      - {name: train-model, path: /tmp/inputs/input-3/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
    metadata:
      annotations: {container.apparmor.security.beta.kubernetes.io/main: unconfined,
        container.apparmor.security.beta.kubernetes.io/wait: unconfined}
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: checkout
    container:
      args:
      - |
        set -euo pipefail

        git clone --depth=1 git@github.com:kubernetes-analysis/kubernetes-analysis
        pushd kubernetes-analysis
        if [[ -n "{{inputs.parameters.pr}}" ]]; then
            curl -L https://github.com/kubernetes-analysis/kubernetes-analysis/pull/{{inputs.parameters.pr}}.patch                         > ../pr.patch
            git apply ../pr.patch
            git add .
            git commit -m "Apply patch"
        fi
        popd

        mkdir -p /out
        echo copying outputs
        cp -r kubernetes-analysis /out/kubernetes-analysis
      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      parameters:
      - {name: pr}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
      - {name: checkout-repo, path: /out/kubernetes-analysis}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: commit-changes
    container:
      args:
      - |+
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis
        cp -r /tmp/inputs/input-1/data data/api.tar.xz
        cp -r /tmp/inputs/input-2/data .update
        cp -r /tmp/inputs/input-3/data data/data.tar.xz
        cp -r /tmp/inputs/input-4/data assets
        cp -r /tmp/inputs/input-5/data data/vectorizer.pickle
        cp -r /tmp/inputs/input-6/data data/selector.pickle
        cp -r /tmp/inputs/input-7/data data/model.h5

        echo "git diff:"
        git diff --name-only

        mv assets/data/*.svg assets/
        git add .
        git commit --allow-empty -m "Update data [skip]"
        if [[ -z "{{inputs.parameters.pr}}" ]]; then
            git push
        fi

      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      parameters:
      - {name: pr}
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
      - {name: update-api-api, path: /tmp/inputs/input-1/data}
      - {name: update-api-update-file, path: /tmp/inputs/input-2/data}
      - {name: update-data-data, path: /tmp/inputs/input-3/data}
      - {name: update-assets-assets, path: /tmp/inputs/input-4/data}
      - {name: train-vectorizer, path: /tmp/inputs/input-5/data}
      - {name: train-selector, path: /tmp/inputs/input-6/data}
      - {name: train-model, path: /tmp/inputs/input-7/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: katib-experiment
    container:
      args:
      - |
        set -euo pipefail

        rm -rf /pv/kubernetes-analysis
        git clone https://github.com/saschagrunert/kubernetes-analysis /pv/kubernetes-analysis
        python /ml/launch_experiment.py --name katib-experiment --namespace kubeflow --maxTrialCount 1 --parallelTrialCount 1 --objectiveConfig '{"type": "maximize", "goal": 0.8, "objectiveMetricName": "Accuracy"}' --algorithmConfig '{"algorithmName": "random"}' --trialTemplate '{"goTemplate": {"rawTemplate": "{\"apiVersion\": \"kubeflow.org/v1\", \"kind\": \"TFJob\", \"metadata\": {\"name\": \"{{.Trial}}\", \"namespace\": \"{{.NameSpace}}\"}, \"spec\": {\"tfReplicaSpecs\": {\"Worker\": {\"replicas\": 1, \"restartPolicy\": \"OnFailure\", \"template\": {\"spec\": {\"containers\": [{\"name\": \"tensorflow\", \"image\": \"quay.io/saschagrunert/kubernetes-analysis:latest\", \"imagePullPolicy\": \"Always\", \"command\": [\"bash\", \"-c\"], \"args\": [\"cd data/kubernetes-analysis ;\", \"git fetch origin master ;\", \"git checkout master ;\", \"./main tune {{- with .HyperParameters}} {{- range .}} {{.Name}}={{.Value}} {{- end}} {{- end}}\"], \"volumeMounts\": [{\"mountPath\": \"/data\", \"name\": \"nfs-storage\"}]}], \"volumes\": [{\"name\": \"nfs-storage\", \"persistentVolumeClaim\": {\"claimName\": \"pipeline-pv\"}}]}}}}}}"}}' --parameters '[{"name": "--layers", "parameterType": "int", "feasibleSpace": {"min": "1", "max": "3"}}, {"name": "--units", "parameterType": "int", "feasibleSpace": {"min": "8", "max": "16"}}]' --metricsCollector '{"collector": {"kind": "StdOut"}}' --experimentTimeoutMinutes '15' --deleteAfterDone True --outputFile results/params

        mkdir -p /out/results
        echo copying outputs
        cp -r results/params /out/results/params
      command: [bash, -c]
      image: mbu93/katib-launcher:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
      - {mountPath: /pv, name: pvolume-b9e658711a70a378fc2f648d144c9b62db9baf69ba848963c7274f7}
    outputs:
      parameters:
      - name: katib-experiment-params
        valueFrom: {path: /out/results/params}
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
      - {name: katib-experiment-params, path: /out/results/params}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: pvolume-b9e658711a70a378fc2f648d144c9b62db9baf69ba848963c7274f7
      persistentVolumeClaim: {claimName: pipeline-pv}
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: kubernetes-analysis
    inputs:
      parameters:
      - {name: commit}
      - {name: pr}
    dag:
      tasks:
      - name: build-image
        template: build-image
        dependencies: [checkout, predict, train]
        arguments:
          parameters:
          - {name: commit, value: '{{inputs.parameters.commit}}'}
          - {name: pr, value: '{{inputs.parameters.pr}}'}
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
          - {name: train-model, from: '{{tasks.train.outputs.artifacts.train-model}}'}
          - {name: train-selector, from: '{{tasks.train.outputs.artifacts.train-selector}}'}
          - {name: train-vectorizer, from: '{{tasks.train.outputs.artifacts.train-vectorizer}}'}
      - name: checkout
        template: checkout
        arguments:
          parameters:
          - {name: pr, value: '{{inputs.parameters.pr}}'}
      - name: commit-changes
        template: commit-changes
        dependencies: [build-image, checkout, train, update-api, update-assets, update-data]
        arguments:
          parameters:
          - {name: pr, value: '{{inputs.parameters.pr}}'}
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
          - {name: train-model, from: '{{tasks.train.outputs.artifacts.train-model}}'}
          - {name: train-selector, from: '{{tasks.train.outputs.artifacts.train-selector}}'}
          - {name: train-vectorizer, from: '{{tasks.train.outputs.artifacts.train-vectorizer}}'}
          - {name: update-api-api, from: '{{tasks.update-api.outputs.artifacts.update-api-api}}'}
          - {name: update-api-update-file, from: '{{tasks.update-api.outputs.artifacts.update-api-update-file}}'}
          - {name: update-assets-assets, from: '{{tasks.update-assets.outputs.artifacts.update-assets-assets}}'}
          - {name: update-data-data, from: '{{tasks.update-data.outputs.artifacts.update-data-data}}'}
      - name: katib-experiment
        template: katib-experiment
        dependencies: [update-data]
      - name: predict
        template: predict
        dependencies: [checkout, train]
        arguments:
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
          - {name: train-model, from: '{{tasks.train.outputs.artifacts.train-model}}'}
          - {name: train-selector, from: '{{tasks.train.outputs.artifacts.train-selector}}'}
          - {name: train-vectorizer, from: '{{tasks.train.outputs.artifacts.train-vectorizer}}'}
      - name: rollout
        template: rollout
        dependencies: [checkout, commit-changes]
        arguments:
          parameters:
          - {name: commit, value: '{{inputs.parameters.commit}}'}
          - {name: pr, value: '{{inputs.parameters.pr}}'}
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
      - name: to-args
        template: to-args
        dependencies: [katib-experiment]
        arguments:
          parameters:
          - {name: katib-experiment-params, value: '{{tasks.katib-experiment.outputs.parameters.katib-experiment-params}}'}
      - name: train
        template: train
        dependencies: [checkout, katib-experiment, to-args, update-data]
        arguments:
          parameters:
          - {name: to-args-output, value: '{{tasks.to-args.outputs.parameters.to-args-output}}'}
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
          - {name: update-data-data, from: '{{tasks.update-data.outputs.artifacts.update-data-data}}'}
      - name: update-api
        template: update-api
        dependencies: [checkout]
        arguments:
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
      - name: update-assets
        template: update-assets
        dependencies: [checkout, update-data]
        arguments:
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
          - {name: update-data-data, from: '{{tasks.update-data.outputs.artifacts.update-data-data}}'}
      - name: update-data
        template: update-data
        dependencies: [checkout, update-api]
        arguments:
          artifacts:
          - {name: checkout-repo, from: '{{tasks.checkout.outputs.artifacts.checkout-repo}}'}
          - {name: update-api-api, from: '{{tasks.update-api.outputs.artifacts.update-api-api}}'}
  - name: predict
    container:
      args:
      - |
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis
        cp -r /tmp/inputs/input-1/data data/vectorizer.pickle
        cp -r /tmp/inputs/input-2/data data/selector.pickle
        cp -r /tmp/inputs/input-3/data data/model.h5

        echo "git diff:"
        git diff --name-only
        ./main predict --test
      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
      - {name: train-vectorizer, path: /tmp/inputs/input-1/data}
      - {name: train-selector, path: /tmp/inputs/input-2/data}
      - {name: train-model, path: /tmp/inputs/input-3/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: rollout
    container:
      args:
      - |+
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis

        echo "git diff:"
        git diff --name-only

        if [[ -n "{{inputs.parameters.pr}}" ]]; then
            echo Skipping rollout since this is a PR
            sleep 10
            exit 0
        fi

        ./main rollout -t {{inputs.parameters.commit}}

      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      parameters:
      - {name: commit}
      - {name: pr}
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: to-args
    container:
      args: [--experiment-result, '{{inputs.parameters.katib-experiment-params}}',
        '----output-paths', /tmp/outputs/Output/data]
      command:
      - python3
      - -u
      - -c
      - |
        def to_args(experiment_result)  :
            import json
            r = json.loads(experiment_result)
            args = []
            for hp in r:
                print(hp)
                args.append("%s %s" % (hp["name"], hp["value"]))

            return " ".join(args)

        def _serialize_str(str_value: str) -> str:
            if not isinstance(str_value, str):
                raise TypeError('Value "{}" has type "{}" instead of str.'.format(str(str_value), str(type(str_value))))
            return str_value

        import argparse
        _parser = argparse.ArgumentParser(prog='To args', description='')
        _parser.add_argument("--experiment-result", dest="experiment_result", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = to_args(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_str,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: tensorflow/tensorflow:1.13.2-py3
    inputs:
      parameters:
      - {name: katib-experiment-params}
    outputs:
      parameters:
      - name: to-args-output
        valueFrom: {path: /tmp/outputs/Output/data}
      artifacts:
      - {name: to-args-output, path: /tmp/outputs/Output/data}
    metadata:
      annotations: {pipelines.kubeflow.org/component_spec: '{"inputs": [{"name": "experiment_result"}],
          "name": "To args", "outputs": [{"name": "Output", "type": "String"}]}'}
  - name: train
    container:
      args:
      - |
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis
        cp -r /tmp/inputs/input-1/data data/data.tar.xz

        echo "git diff:"
        git diff --name-only
        ./main train {{inputs.parameters.to-args-output}}
        mkdir -p /out/data
        echo copying outputs
        cp -r data/vectorizer.pickle /out/data/vectorizer.pickle
        mkdir -p /out/data
        echo copying outputs
        cp -r data/selector.pickle /out/data/selector.pickle
        mkdir -p /out/data
        echo copying outputs
        cp -r data/model.h5 /out/data/model.h5
      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      resources:
        limits: {nvidia.com/gpu: '2'}
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      parameters:
      - {name: to-args-output}
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
      - {name: update-data-data, path: /tmp/inputs/input-1/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
      - {name: train-model, path: /out/data/model.h5}
      - {name: train-selector, path: /out/data/selector.pickle}
      - {name: train-vectorizer, path: /out/data/vectorizer.pickle}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: update-api
    container:
      args:
      - |
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis

        echo "git diff:"
        git diff --name-only

        export GITHUB_TOKEN=$(cat /secrets/github/GITHUB_TOKEN)
        ./main export --update-api

        mkdir -p /out/data
        echo copying outputs
        cp -r data/api.tar.xz /out/data/api.tar.xz
        mkdir -p /out
        echo copying outputs
        cp -r .update /out/.update
      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
      - {name: update-api-api, path: /out/data/api.tar.xz}
      - {name: update-api-update-file, path: /out/.update}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: update-assets
    container:
      args:
      - |
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis
        cp -r /tmp/inputs/input-1/data data/data.tar.xz

        echo "git diff:"
        git diff --name-only
        make assets
        mkdir -p /out
        echo copying outputs
        cp -r assets /out/assets
      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
      - {name: update-data-data, path: /tmp/inputs/input-1/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
      - {name: update-assets-assets, path: /out/assets}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  - name: update-data
    container:
      args:
      - |
        set -euo pipefail
        cp -r /tmp/inputs/input-0/data kubernetes-analysis
        cd kubernetes-analysis
        cp -r /tmp/inputs/input-1/data data/api.tar.xz

        echo "git diff:"
        git diff --name-only
        ./main export --update-data
        mkdir -p /out/data
        echo copying outputs
        cp -r data/data.tar.xz /out/data/data.tar.xz
      command: [bash, -c]
      image: quay.io/saschagrunert/kubernetes-analysis:latest
      imagePullPolicy: Always
      volumeMounts:
      - {mountPath: /out, name: output-artifacts}
      - {mountPath: /secrets/github, name: github-token, readOnly: true}
      - {mountPath: /secrets/quay, name: quay, readOnly: true}
      - {mountPath: /root/.ssh, name: ssh-key, readOnly: true}
    inputs:
      artifacts:
      - {name: checkout-repo, path: /tmp/inputs/input-0/data}
      - {name: update-api-api, path: /tmp/inputs/input-1/data}
    outputs:
      artifacts:
      - {name: mlpipeline-ui-metadata, path: /out/mlpipeline-ui-metadata.json}
      - {name: mlpipeline-metrics, path: /out/mlpipeline-metrics.json}
      - {name: update-data-data, path: /out/data/data.tar.xz}
    metadata:
      labels: {pipelines.kubeflow.org/pipeline-sdk-type: kfp}
    volumes:
    - name: github-token
      secret: {secretName: github-token}
    - emptyDir: {}
      name: output-artifacts
    - name: quay
      secret: {secretName: quay}
    - name: ssh-key
      secret: {defaultMode: 384, secretName: ssh-key}
  arguments:
    parameters:
    - {name: pr, value: ''}
    - {name: commit, value: ''}
  serviceAccountName: pipeline-runner
